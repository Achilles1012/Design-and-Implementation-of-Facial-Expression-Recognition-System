{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision import datasets\n",
    "from torchinfo import summary\n",
    "from torchvision.transforms import ToTensor\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the current device (GPU)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    # Get the name of the GPU\n",
    "    gpu_name = torch.cuda.get_device_name(device)\n",
    "    # Get the total memory of the GPU\n",
    "    gpu_properties = torch.cuda.get_device_properties(device)\n",
    "    total_memory = gpu_properties.total_memory / (1024 ** 3)  # Convert bytes to GB\n",
    "    \n",
    "    print(f\"Using GPU: {gpu_name}\")\n",
    "    print(f\"Total GPU memory: {total_memory:.2f} GB\")\n",
    "else:\n",
    "    print(\"No GPU available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained ViT model and processor\n",
    "model_name = \"google/vit-base-patch16-224-in21k\"\n",
    "pretrained_vit = ViTForImageClassification.from_pretrained(model_name).to(device)\n",
    "processor = ViTImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "# Modify the classifier head\n",
    "class_names = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "num_classes = len(class_names)\n",
    "pretrained_vit.classifier = nn.Linear(in_features=768, out_features=num_classes).to(device)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seeds(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seeds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a summary using torchinfo\n",
    "summary(model=pretrained_vit,\n",
    "        input_size=(32, 3, 224, 224), # (batch_size, color_channels, height, width)\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset, processor):\n",
    "        self.dataset = dataset\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[idx]        \n",
    "        # Convert Grayscale to 3-channel RGB\n",
    "        if img.mode == 'L':\n",
    "            img = np.stack([img] * 3, axis=-1)\n",
    "            img = Image.fromarray(img)\n",
    "        \n",
    "        img = self.processor(images=img, return_tensors=\"pt\")[\"pixel_values\"].squeeze(0)\n",
    "        return img, label\n",
    "\n",
    "def create_dataloaders(data_dir: str, processor: ViTImageProcessor, batch_size: int, validation_split: float=0.2, test_split: float=0.1):\n",
    "    dataset = datasets.ImageFolder(data_dir)\n",
    "    class_names = dataset.classes\n",
    "    dataset_size = len(dataset)\n",
    "    \n",
    "    test_size = int(test_split * dataset_size)\n",
    "    val_size = int(validation_split * dataset_size)\n",
    "    train_size = dataset_size - val_size - test_size\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(123)\n",
    "    )\n",
    "    \n",
    "    train_dataset = CustomDataset(train_dataset, processor)\n",
    "    val_dataset = CustomDataset(val_dataset, processor)\n",
    "    test_dataset = CustomDataset(test_dataset, processor)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_dataloader, val_dataloader, test_dataloader, class_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "data_dir = 'Expw-F'\n",
    "train_dataloader, val_dataloader, test_dataloader, class_names = create_dataloaders(\n",
    "                                                                                    data_dir,\n",
    "                                                                                    processor,\n",
    "                                                                                    batch_size=32\n",
    "                                                                                    )\n",
    "\n",
    "# Check the sizes of the datasets\n",
    "print(f\"Training dataset size: {len(train_dataloader.dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataloader.dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataloader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: iterate over the training dataset\n",
    "for images, labels in train_dataloader:\n",
    "    print(images.shape, labels.shape)  # Example output: torch.Size([32, 3, 112, 112]) torch.Size([32])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the mean and standard deviation used for normalization\n",
    "mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "std = torch.tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "# Get a batch of images\n",
    "image_batch, label_batch = next(iter(train_dataloader))\n",
    "\n",
    "# Get a single image from the batch\n",
    "image, label = image_batch[0], label_batch[0]\n",
    "\n",
    "# Unnormalize the image\n",
    "image = image * std[:, None, None] + mean[:, None, None]\n",
    "\n",
    "# View the batch shapes\n",
    "print(image.shape, label)\n",
    "\n",
    "# Plot image with matplotlib\n",
    "plt.imshow(image.permute(1, 2, 0)) # rearrange image dimensions to suit matplotlib [color_channels, height, width] -> [height, width, color_channels]\n",
    "plt.title(class_names[label])\n",
    "plt.axis('off') # Turn off axis\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer and loss function\n",
    "optimizer = torch.optim.Adam(params=pretrained_vit.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, val_dataloader, optimizer, loss_fn, epochs, device, checkpoint_dir=\"checkpointsADAM\"):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        # Training loop with progress bar\n",
    "        with tqdm(total=len(train_dataloader), desc=f\"Epoch {epoch+1}/{epochs}\", unit='batch') as pbar:\n",
    "            for images, labels in train_dataloader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()  # Zero the gradients\n",
    "                outputs = model(images)  # Forward pass\n",
    "                logits = outputs.logits\n",
    "                loss = loss_fn(logits, labels)  # Compute loss\n",
    "                loss.backward()  # Backward pass\n",
    "                optimizer.step()  # Update parameters\n",
    "\n",
    "                running_train_loss += loss.item()\n",
    "\n",
    "                # Calculate training accuracy\n",
    "                _, predicted_train = torch.max(logits, 1)\n",
    "                total_train += labels.size(0)\n",
    "                correct_train += (predicted_train == labels).sum().item()\n",
    "\n",
    "                pbar.set_postfix(loss=running_train_loss / (pbar.n + 1))  # Update the progress bar\n",
    "                pbar.update(1)  # Update progress bar\n",
    "\n",
    "        epoch_train_loss = running_train_loss / len(train_dataloader)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accuracy = correct_train / total_train\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {epoch_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        running_val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_dataloader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                logits = outputs.logits\n",
    "                loss = loss_fn(logits, labels)  # Compute validation loss\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                _, predicted_val = torch.max(logits, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted_val == labels).sum().item()\n",
    "\n",
    "            epoch_val_loss = running_val_loss / len(val_dataloader)\n",
    "            val_losses.append(epoch_val_loss)\n",
    "            val_accuracy = correct_val / total_val\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            print(f\"Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "            # Save checkpoint if validation accuracy improves\n",
    "            if val_accuracy > best_accuracy:\n",
    "                best_accuracy = save_checkpoint(model, epoch, val_accuracy, best_accuracy, checkpoint_dir)\n",
    "\n",
    "    return train_losses, train_accuracies, val_losses, val_accuracies\n",
    "\n",
    "# Checkpoint function to save the model\n",
    "def save_checkpoint(model, epoch, accuracy, best_accuracy, checkpoint_dir=\"checkpointsADAM\"):\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"model_epoch_{epoch+1}_acc_{accuracy:.4f}.pth\")\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "    return accuracy  # Update the best accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_losses, train_accuracies, val_losses, val_accuracies = train_model(pretrained_vit, train_dataloader, val_dataloader, optimizer, loss_fn, epochs=5, device=device) # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting Loss and Accuracy\n",
    "def plot_metrics(train_losses, val_accuracies):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label='Training Loss', color='blue')\n",
    "    plt.title('Training Loss vs Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xticks(epochs)\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, val_accuracies, label='Validation Accuracy', color='orange')\n",
    "    plt.title('Validation Accuracy vs Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(epochs)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the plot function\n",
    "plot_metrics(train_losses, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(model, dataloader, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images).logits\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=range(num_classes))\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "pretrained_vit.load_state_dict(torch.load(best_checkpoint_path))\n",
    "print(f\"Loaded best checkpoint from {best_checkpoint_path}\")\n",
    "\"\"\"\n",
    "# Call the plot function on the validation set\n",
    "plot_confusion_matrix(pretrained_vit, val_dataloader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define data to save\n",
    "data = {\n",
    "    'epoch': range(1, len(train_losses) + 1),\n",
    "    'train_loss': train_losses,\n",
    "    'train_accuracy': train_accuracies,\n",
    "    'val_loss': val_losses,\n",
    "    'val_accuracy': val_accuracies\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "csv_filename = 'training_metrics_ADAM.csv'\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Training metrics saved to {csv_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
